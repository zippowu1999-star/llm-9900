#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆAIä»£ç† - åªåšé¢„æµ‹ï¼Œè¿”å›é”€å”®æ•°æ®
"""

import pandas as pd
import numpy as np
import time
import logging
import json
import re
import asyncio
from typing import Dict, List
from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI
from data_loader import DataLoader
from config import OPENAI_API_KEY, OPENAI_MODEL

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleAgent:
    """ç®€åŒ–ç‰ˆAIä»£ç† - åªåšé”€å”®é¢„æµ‹"""
    
    def __init__(self, api_key: str = None, model: str = None, data_loader: DataLoader = None):
        self.api_key = api_key or OPENAI_API_KEY
        self.model = model or OPENAI_MODEL
        if not self.api_key:
            raise ValueError("OpenAI APIå¯†é’¥æœªè®¾ç½®")
        
        self.client = OpenAI(api_key=self.api_key)
        self.data_loader = data_loader if data_loader is not None else DataLoader()
        
        # é¢„è®¡ç®—é”€å”®ç»Ÿè®¡æ‘˜è¦ï¼Œé¿å…é‡å¤è®¡ç®—
        self.sales_summary = None
        self._prepare_sales_summary()
        
        logger.info(f"ç®€åŒ–AIä»£ç†åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model}")
    
    def _prepare_sales_summary(self):
        """é¢„è®¡ç®—æ‰€æœ‰å•†åº—å’Œäº§å“ç±»åˆ«çš„é”€å”®ç»Ÿè®¡ï¼Œé¿å…é‡å¤è®¡ç®—"""
        logger.info("ğŸš€ é¢„è®¡ç®—é”€å”®ç»Ÿè®¡æ‘˜è¦...")
        
        try:
            train_data = self.data_loader.train_data
            
            # è®¡ç®—åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
            summary = (
                train_data.groupby(['store_nbr', 'family'])['sales']
                .agg(
                    avg_sales='mean',
                    min_sales='min', 
                    max_sales='max',
                    zero_ratio=lambda x: (x == 0).mean()
                )
                .reset_index()
            )
            
            # è®¡ç®—æœ€è¿‘7å¤©å¹³å‡å€¼
            recent_avg_data = []
            for (store_nbr, family), group in train_data.groupby(['store_nbr', 'family']):
                recent_avg = group.tail(7)['sales'].mean() if len(group) > 0 else 0.0
                recent_avg_data.append({
                    'store_nbr': store_nbr,
                    'family': family,
                    'recent_avg': recent_avg
                })
            
            recent_avg_df = pd.DataFrame(recent_avg_data)
            
            # åˆå¹¶æ•°æ®
            self.sales_summary = summary.merge(
                recent_avg_df, 
                on=['store_nbr', 'family'], 
                how='left'
            )
            
            logger.info(f"âœ… é”€å”®ç»Ÿè®¡æ‘˜è¦è®¡ç®—å®Œæˆï¼Œå…± {len(self.sales_summary):,} ä¸ªå•†åº—-äº§å“ç»„åˆ")
            
        except Exception as e:
            logger.error(f"é¢„è®¡ç®—é”€å”®ç»Ÿè®¡å¤±è´¥: {e}")
            self.sales_summary = pd.DataFrame()
    
    def _get_historical_sales(self, store_nbr: int, family: str) -> Dict:
        """è·å–å†å²é”€å”®æ•°æ® - ä½¿ç”¨é¢„è®¡ç®—çš„ç»“æœï¼ŒO(1)æŸ¥è¯¢"""
        try:
            # ä»é¢„è®¡ç®—çš„æ‘˜è¦ä¸­æŸ¥æ‰¾
            if self.sales_summary is not None and len(self.sales_summary) > 0:
                row = self.sales_summary[
                    (self.sales_summary['store_nbr'] == store_nbr) &
                    (self.sales_summary['family'] == family)
                ]
                
                if len(row) > 0:
                    return {
                        'avg_sales': float(row.iloc[0]['avg_sales']),
                        'recent_avg': float(row.iloc[0]['recent_avg']),
                        'min_sales': float(row.iloc[0]['min_sales']),
                        'max_sales': float(row.iloc[0]['max_sales']),
                        'zero_ratio': float(row.iloc[0]['zero_ratio'])
                    }
            
            # å¦‚æœé¢„è®¡ç®—æ•°æ®ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤å€¼
            return {
                'avg_sales': 0.0,
                'recent_avg': 0.0,
                'min_sales': 0.0,
                'max_sales': 0.0,
                'zero_ratio': 1.0
            }
        except Exception as e:
            logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}")
            return {
                'avg_sales': 0.0,
                'recent_avg': 0.0,
                'min_sales': 0.0,
                'max_sales': 0.0,
                'zero_ratio': 1.0
            }
    
    def _get_data_summary(self) -> Dict:
        """è·å–æ•°æ®æ‘˜è¦ä¿¡æ¯"""
        try:
            train_data = self.data_loader.train_data
            
            return {
                'total_records': len(train_data),
                'date_range': {
                    'start': str(train_data['date'].min()),
                    'end': str(train_data['date'].max())
                },
                'stores_count': train_data['store_nbr'].nunique(),
                'families_count': train_data['family'].nunique(),
                'sales_stats': {
                    'mean': train_data['sales'].mean(),
                    'median': train_data['sales'].median(),
                    'std': train_data['sales'].std(),
                    'min': train_data['sales'].min(),
                    'max': train_data['sales'].max()
                }
            }
        except Exception as e:
            logger.error(f"è·å–æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return {
                'total_records': 0,
                'date_range': {'start': '', 'end': ''},
                'stores_count': 0,
                'families_count': 0,
                'sales_stats': {
                    'mean': 0.0,
                    'median': 0.0,
                    'std': 0.0,
                    'min': 0.0,
                    'max': 0.0
                }
            }
    
    def _get_context_info(self, sample_data: Dict) -> Dict:
        """è·å–æ—¥æœŸç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæ²¹ä»·ã€èŠ‚å‡æ—¥ç­‰ï¼‰"""
        try:
            date_str = sample_data.get('date', '')
            if not date_str:
                return {
                    'oil_price': 'N/A',
                    'is_holiday': 'N/A', 
                    'holiday_type': 'N/A',
                    'recent_oil_avg': 'N/A'
                }
            
            # è·å–æ²¹ä»·ä¿¡æ¯
            oil_data = self.data_loader.oil_data
            target_date = pd.to_datetime(date_str)
            
            # å½“å‰æ—¥æœŸæ²¹ä»·
            oil_row = oil_data[oil_data['date'] == target_date]
            oil_price = oil_row['dcoilwtico'].iloc[0] if len(oil_row) > 0 else None
            
            # æœ€è¿‘7å¤©å¹³å‡æ²¹ä»·
            recent_dates = oil_data[oil_data['date'] <= target_date].tail(7)
            recent_oil_avg = recent_dates['dcoilwtico'].mean() if len(recent_dates) > 0 else None
            
            # è·å–èŠ‚å‡æ—¥ä¿¡æ¯
            holidays_data = self.data_loader.holidays_data
            holiday_row = holidays_data[holidays_data['date'] == target_date]
            is_holiday = len(holiday_row) > 0
            holiday_type = holiday_row['type'].iloc[0] if len(holiday_row) > 0 else None
            
            return {
                'oil_price': f"{oil_price:.2f}" if oil_price is not None else 'N/A',
                'is_holiday': 'æ˜¯' if is_holiday else 'å¦',
                'holiday_type': holiday_type if holiday_type else 'æ— ',
                'recent_oil_avg': f"{recent_oil_avg:.2f}" if recent_oil_avg is not None else 'N/A'
            }
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'oil_price': 'N/A',
                'is_holiday': 'N/A',
                'holiday_type': 'N/A', 
                'recent_oil_avg': 'N/A'
            }
    
    def predict_sales(self, sample_data: Dict, retry_count: int = 0) -> Dict:
        """é¢„æµ‹å•ä¸ªæ ·æœ¬çš„é”€å”®é¢"""
        try:
            # è·å–å†å²æ•°æ®ä¸Šä¸‹æ–‡
            store_nbr = sample_data.get('store_nbr', 1)
            family = sample_data.get('family', '')
            
            # ä»è®­ç»ƒæ•°æ®ä¸­è·å–è¯¥å•†åº—å’Œäº§å“ç±»åˆ«çš„å†å²é”€å”®æ•°æ®
            historical_data = self._get_historical_sales(store_nbr, family)
            
            # è·å–æ›´è¯¦ç»†çš„æ•°æ®æ‘˜è¦
            data_summary = self._get_data_summary()
            
            # è·å–èŠ‚å‡æ—¥å’Œæ²¹ä»·ä¸Šä¸‹æ–‡
            context_info = self._get_context_info(sample_data)
            
            prompt = f"""
åŸºäºä»¥ä¸‹è¯¦ç»†æ•°æ®é¢„æµ‹é”€å”®é¢ï¼š

é¢„æµ‹æ ·æœ¬:
- å•†åº—ç¼–å·: {sample_data.get('store_nbr', 'N/A')}
- äº§å“ç±»åˆ«: {sample_data.get('family', 'N/A')}
- æ—¥æœŸ: {sample_data.get('date', 'N/A')}
- ä¿ƒé”€çŠ¶æ€: {sample_data.get('onpromotion', 'N/A')}

å…¨å±€æ•°æ®æ‘˜è¦:
- æ€»è®°å½•æ•°: {data_summary['total_records']:,}
- æ—¥æœŸèŒƒå›´: {data_summary['date_range']['start']} åˆ° {data_summary['date_range']['end']}
- å•†åº—æ•°é‡: {data_summary['stores_count']}
- äº§å“ç±»åˆ«æ•°é‡: {data_summary['families_count']}
- å…¨å±€å¹³å‡é”€å”®é¢: ${data_summary['sales_stats']['mean']:.2f}
- å…¨å±€é”€å”®é¢èŒƒå›´: ${data_summary['sales_stats']['min']:.2f} - ${data_summary['sales_stats']['max']:.2f}

è¯¥å•†åº—è¯¥äº§å“ç±»åˆ«å†å²æ•°æ®:
- å¹³å‡é”€å”®é¢: ${historical_data.get('avg_sales', 0):.2f}
- æœ€è¿‘7å¤©å¹³å‡é”€å”®é¢: ${historical_data.get('recent_avg', 0):.2f}
- å†å²é”€å”®é¢èŒƒå›´: ${historical_data.get('min_sales', 0):.2f} - ${historical_data.get('max_sales', 0):.2f}
- é›¶é”€å”®å¤©æ•°å æ¯”: {historical_data.get('zero_ratio', 0):.1%}

æ—¥æœŸä¸Šä¸‹æ–‡ä¿¡æ¯:
- æ²¹ä»·: ${context_info.get('oil_price', 'N/A')}
- æ˜¯å¦èŠ‚å‡æ—¥: {context_info.get('is_holiday', 'N/A')}
- èŠ‚å‡æ—¥ç±»å‹: {context_info.get('holiday_type', 'N/A')}
- æœ€è¿‘7å¤©å¹³å‡æ²¹ä»·: ${context_info.get('recent_oil_avg', 'N/A')}

è¯·ç»¼åˆè€ƒè™‘æ²¹ä»·æ³¢åŠ¨ã€èŠ‚å‡æ—¥æ•ˆåº”ã€ä¿ƒé”€çŠ¶æ€å’Œå†å²é”€å”®æ¨¡å¼è¿›è¡Œé¢„æµ‹ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼å›ç­”ï¼š
```json
{{
    "predicted_sales": æ•°å€¼
}}
```
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªé”€å”®é¢„æµ‹ä¸“å®¶ï¼Œè¯·æ ¹æ®ç»™å®šä¿¡æ¯é¢„æµ‹é”€å”®é¢ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=50,  # å‡å°‘tokenä½¿ç”¨
                temperature=0.1
            )
            
            # è§£æJSONå“åº”
            response_text = response.choices[0].message.content
            json_match = re.search(r'\{[^}]*"predicted_sales"[^}]*\}', response_text)
            
            if json_match:
                result = json.loads(json_match.group())
                predicted_sales = result.get('predicted_sales', 0.0)
            else:
                logger.warning("JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                predicted_sales = 0.0
            
            return {
                'id': sample_data.get('id', ''),
                'predicted_sales': float(predicted_sales)
            }
            
        except Exception as e:
            error_msg = str(e)
            
            # å¤„ç†é€Ÿç‡é™åˆ¶
            if "429" in error_msg and retry_count < 3:
                logger.warning(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…é‡è¯•... (ç¬¬{retry_count + 1}æ¬¡)")
                time.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
                return self.predict_sales(sample_data, retry_count + 1)
            
            logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
            return {
                'id': sample_data.get('id', ''),
                'predicted_sales': 0.0
            }
    
    def batch_predict(self, test_data: pd.DataFrame, batch_size: int = 1000) -> List[Dict]:
        """æ‰¹é‡é¢„æµ‹"""
        logger.info(f"å¼€å§‹æ‰¹é‡é¢„æµ‹ï¼Œæ€»æ ·æœ¬æ•°: {len(test_data):,}")
        
        all_predictions = []
        total_samples = len(test_data)
        num_batches = (total_samples + batch_size - 1) // batch_size
        
        for i in range(0, total_samples, batch_size):
            batch_end = min(i + batch_size, total_samples)
            batch_data = test_data.iloc[i:batch_end]
            batch_num = (i // batch_size) + 1
            
            logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_num}/{num_batches} (æ ·æœ¬ {i+1:,}-{batch_end:,})")
            
            # ä¸²è¡Œé¢„æµ‹ï¼Œé¿å…å¹¶å‘è¯·æ±‚å¯¼è‡´é€Ÿç‡é™åˆ¶
            batch_predictions = []
            for _, row in batch_data.iterrows():
                try:
                    result = self.predict_sales(row.to_dict())
                    batch_predictions.append(result)
                    logger.info(f"   âœ… é¢„æµ‹å®Œæˆ: ID {result['id']}, é”€å”®é¢ ${result['predicted_sales']:.2f}")
                except Exception as e:
                    logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
                    batch_predictions.append({
                        'id': row.get('id', ''),
                        'predicted_sales': 0.0
                    })
            
            # æ‰¹æ¬¡é—´æ·»åŠ å»¶è¿Ÿï¼Œé¿å…é€Ÿç‡é™åˆ¶
            if batch_num < num_batches:
                time.sleep(1)
            
            all_predictions.extend(batch_predictions)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = (batch_end / total_samples) * 100
            logger.info(f"   âœ… æ‰¹æ¬¡å®Œæˆï¼Œè¿›åº¦: {progress:.1f}%")
        
        return all_predictions
