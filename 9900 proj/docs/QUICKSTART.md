# å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹AI Agentæ•°æ®åˆ†æç³»ç»Ÿã€‚

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

## âš™ï¸ é…ç½®ç¯å¢ƒ

1. **é…ç½®Kaggle API**

ä» [Kaggleè´¦æˆ·è®¾ç½®](https://www.kaggle.com/settings/account) ä¸‹è½½ `kaggle.json`

```bash
# Linux/Mac
mkdir -p ~/.kaggle
mv kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json

# æˆ–è€…ä½¿ç”¨ç¯å¢ƒå˜é‡
export KAGGLE_USERNAME=your_username
export KAGGLE_KEY=your_api_key
```

2. **å®‰è£…å’Œå¯åŠ¨Ollama**

```bash
# ä¸‹è½½å¹¶å®‰è£…: https://ollama.ai/

# æ‹‰å–æ¨¡å‹
ollama pull llama3

# å¯åŠ¨æœåŠ¡ï¼ˆé»˜è®¤åœ¨11434ç«¯å£ï¼‰
ollama serve
```

## ğŸš€ åŸºç¡€ä½¿ç”¨

### æ–¹å¼1: ä½¿ç”¨ç¤ºä¾‹ä»£ç 

```bash
python examples/basic_usage.py
```

### æ–¹å¼2: ç¼–å†™è‡ªå·±çš„ä»£ç 

```python
import asyncio
from pathlib import Path
from backend.agents import AgentConfig, AgentType
from backend.agents.example_agent import ExampleAgent

async def main():
    # 1. åˆ›å»ºé…ç½®
    config = AgentConfig(
        agent_type=AgentType.REACT,
        competition_name="my-competition",
        competition_url="https://www.kaggle.com/c/my-competition",
        data_path=Path("data/competitions/my-competition"),
        llm_model="llama3",
        temperature=0.7
    )
    
    # 2. åˆå§‹åŒ–ä»£ç†
    agent = ExampleAgent(config)
    
    # 3. è®¾ç½®å›è°ƒï¼ˆå¯é€‰ï¼‰
    agent.set_callbacks(
        status_callback=lambda s: print(f"çŠ¶æ€: {s.value}"),
        log_callback=lambda m: print(f"æ—¥å¿—: {m}")
    )
    
    # 4. è¿è¡Œ
    problem_description = "ä½ çš„é—®é¢˜æè¿°..."
    data_info = {"columns": [...], "shape": (...)}
    
    result = await agent.run(problem_description, data_info)
    
    # 5. æŸ¥çœ‹ç»“æœ
    print(f"çŠ¶æ€: {result.status.value}")
    print(f"ä»£ç : {result.code_file_path}")
    print(f"æäº¤: {result.submission_file_path}")
    print(f"è€—æ—¶: {result.total_time:.2f}ç§’")
    
    return result

# è¿è¡Œ
asyncio.run(main())
```

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### 1. AgentConfigï¼ˆä»£ç†é…ç½®ï¼‰

é…ç½®ä»£ç†çš„æ‰€æœ‰å‚æ•°ï¼š

```python
config = AgentConfig(
    # å¿…éœ€å‚æ•°
    agent_type=AgentType.REACT,          # ä»£ç†ç±»å‹
    competition_name="competition-name",  # ç«èµ›åç§°
    competition_url="...",                # Kaggleé“¾æ¥
    data_path=Path("..."),                # æ•°æ®è·¯å¾„
    
    # LLMé…ç½®
    llm_model="llama3",                   # æ¨¡å‹åç§°
    temperature=0.7,                      # æ¸©åº¦å‚æ•°
    max_tokens=4096,                      # æœ€å¤§token
    
    # æ‰§è¡Œé…ç½®
    max_execution_time=300,               # è¶…æ—¶ï¼ˆç§’ï¼‰
    max_memory_mb=2048,                   # å†…å­˜é™åˆ¶
    max_retries=3,                        # é‡è¯•æ¬¡æ•°
    
    # è¾“å‡ºé…ç½®
    output_dir=None,                      # è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
    save_intermediate_results=True,       # ä¿å­˜ä¸­é—´ç»“æœ
    verbose=True                          # è¯¦ç»†æ—¥å¿—
)
```

### 2. BaseAgentï¼ˆåŸºç¡€ä»£ç†ï¼‰

æ‰€æœ‰ä»£ç†çš„æŠ½è±¡åŸºç±»ï¼Œå®šä¹‰äº†æ ‡å‡†æ¥å£ï¼š

**å¿…é¡»å®ç°çš„æ–¹æ³•ï¼š**

- `analyze_problem(problem_description)` - åˆ†æé—®é¢˜
- `generate_code(problem_analysis, data_info)` - ç”Ÿæˆä»£ç 
- `execute_code(code)` - æ‰§è¡Œä»£ç 
- `get_metrics()` - è·å–æŒ‡æ ‡

**é€šç”¨æ–¹æ³•ï¼š**

- `run(problem_description, data_info)` - è¿è¡Œå®Œæ•´æµç¨‹
- `set_callbacks(status_callback, log_callback)` - è®¾ç½®å›è°ƒ

### 3. AgentResultï¼ˆæ‰§è¡Œç»“æœï¼‰

åŒ…å«ä»£ç†è¿è¡Œçš„æ‰€æœ‰è¾“å‡ºï¼š

```python
result = await agent.run(...)

# åŸºæœ¬ä¿¡æ¯
result.status                    # çŠ¶æ€ï¼ˆCOMPLETED/FAILEDï¼‰
result.generated_code            # ç”Ÿæˆçš„ä»£ç 
result.code_file_path           # ä»£ç æ–‡ä»¶è·¯å¾„
result.submission_file_path     # submission.csvè·¯å¾„

# æ€§èƒ½æŒ‡æ ‡
result.total_time               # æ€»è€—æ—¶
result.code_generation_time     # ä»£ç ç”Ÿæˆè€—æ—¶
result.execution_time           # æ‰§è¡Œè€—æ—¶
result.llm_calls               # LLMè°ƒç”¨æ¬¡æ•°
result.code_lines              # ä»£ç è¡Œæ•°

# ä¸­é—´è¿‡ç¨‹
result.thoughts                # æ€è€ƒè¿‡ç¨‹
result.actions                 # æ‰§è¡Œçš„åŠ¨ä½œ
result.observations           # è§‚å¯Ÿç»“æœ

# ä¿å­˜ç»“æœ
result.save(Path("result.json"))
```

## ğŸ—ï¸ å®ç°è‡ªå®šä¹‰ä»£ç†

è¦åˆ›å»ºè‡ªå·±çš„ä»£ç†æ¶æ„ï¼Œç»§æ‰¿ `BaseAgent`ï¼š

```python
from backend.agents.base_agent import BaseAgent, AgentConfig

class MyAgent(BaseAgent):
    def __init__(self, config: AgentConfig):
        super().__init__(config)
        # è‡ªå®šä¹‰åˆå§‹åŒ–
        self.llm = self._init_llm()
    
    async def analyze_problem(self, problem_description: str):
        """åˆ†æé—®é¢˜"""
        # è°ƒç”¨LLMåˆ†æ
        analysis = await self.llm.analyze(problem_description)
        self.result.llm_calls += 1
        return analysis
    
    async def generate_code(self, problem_analysis, data_info):
        """ç”Ÿæˆä»£ç """
        # è°ƒç”¨LLMç”Ÿæˆä»£ç 
        code = await self.llm.generate(problem_analysis, data_info)
        self.result.llm_calls += 1
        return code
    
    async def execute_code(self, code: str):
        """æ‰§è¡Œä»£ç """
        # åœ¨æ²™ç®±ä¸­æ‰§è¡Œ
        result = self.executor.run(code)
        return result
    
    def get_metrics(self):
        """è·å–æŒ‡æ ‡"""
        return {
            "total_time": self.result.total_time,
            "llm_calls": self.result.llm_calls,
            # ... å…¶ä»–æŒ‡æ ‡
        }
```

## ğŸ§ª è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_base_agent.py -v

# è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•
pytest tests/ --cov=backend --cov-report=html
```

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
9900pj/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base_agent.py         # âœ“ åŸºç¡€ä»£ç†ï¼ˆå·²å®Œæˆï¼‰
â”‚   â”‚   â”œâ”€â”€ example_agent.py      # âœ“ ç¤ºä¾‹ä»£ç†ï¼ˆå·²å®Œæˆï¼‰
â”‚   â”‚   â”œâ”€â”€ react_agent.py        # TODO: ReActä»£ç†
â”‚   â”‚   â”œâ”€â”€ rag_agent.py          # TODO: RAGä»£ç†
â”‚   â”‚   â””â”€â”€ multi_agent.py        # TODO: Multi-Agent
â”‚   â”œâ”€â”€ kaggle/                   # TODO: Kaggleé›†æˆ
â”‚   â”œâ”€â”€ executor/                 # TODO: ä»£ç æ‰§è¡Œå¼•æ“
â”‚   â”œâ”€â”€ evaluation/               # TODO: è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ logger.py             # âœ“ æ—¥å¿—å·¥å…·ï¼ˆå·²å®Œæˆï¼‰
â”‚   â””â”€â”€ config.py                 # âœ“ é…ç½®ç®¡ç†ï¼ˆå·²å®Œæˆï¼‰
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py          # TODO: Streamlitç•Œé¢
â”œâ”€â”€ data/                         # æ•°æ®ç›®å½•
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ basic_usage.py            # âœ“ åŸºç¡€ç¤ºä¾‹ï¼ˆå·²å®Œæˆï¼‰
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_base_agent.py        # âœ“ æµ‹è¯•ï¼ˆå·²å®Œæˆï¼‰
â””â”€â”€ requirements.txt              # âœ“ ä¾èµ–ï¼ˆå·²å®Œæˆï¼‰
```

## âœ… å½“å‰è¿›åº¦

- âœ… é¡¹ç›®ç»“æ„åˆ›å»º
- âœ… BaseAgentå®ç°
- âœ… é…ç½®ç®¡ç†
- âœ… æ—¥å¿—ç³»ç»Ÿ
- âœ… æµ‹è¯•æ¡†æ¶
- âœ… ç¤ºä¾‹ä»£ç 

**ä¸‹ä¸€æ­¥ï¼š**
1. å®ç°Kaggleæ•°æ®è·å–æ¨¡å—
2. å®ç°ä»£ç æ‰§è¡Œå¼•æ“
3. å®ç°å…·ä½“çš„Agentï¼ˆReActã€RAGã€Multi-Agentï¼‰
4. åˆ›å»ºStreamlitå‰ç«¯ç•Œé¢

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q: Ollamaè¿æ¥å¤±è´¥ï¼Ÿ
```bash
# æ£€æŸ¥Ollamaæ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/tags

# é‡å¯Ollama
ollama serve
```

### Q: Kaggle APIè®¤è¯å¤±è´¥ï¼Ÿ
```bash
# æ£€æŸ¥kaggle.jsonä½ç½®
ls -la ~/.kaggle/kaggle.json

# æ£€æŸ¥æƒé™
chmod 600 ~/.kaggle/kaggle.json
```

### Q: å¦‚ä½•æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼Ÿ
æ—¥å¿—æ–‡ä»¶ä½äº `logs/app_YYYY-MM-DD.log`

### Q: å¦‚ä½•ä¿®æ”¹LLMæ¨¡å‹ï¼Ÿ
åœ¨é…ç½®ä¸­ä¿®æ”¹ `llm_model` å‚æ•°ï¼š
```python
config.llm_model = "llama3:70b"  # ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
config.llm_model = "mistral"     # ä½¿ç”¨å…¶ä»–æ¨¡å‹
```

## ğŸ“– æ›´å¤šæ–‡æ¡£

- [æ¶æ„è®¾è®¡](architecture.md)
- [Agentè¯¦ç»†è¯´æ˜](../backend/agents/README.md)
- [APIæ–‡æ¡£](api.md)

## ğŸ’¬ è·å–å¸®åŠ©

å¦‚æœ‰é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
2. è¿è¡Œæµ‹è¯•éªŒè¯ç¯å¢ƒ
3. æŸ¥çœ‹ç¤ºä¾‹ä»£ç 
4. æäº¤Issueåˆ°GitHub

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿå¼€å§‹ä½ çš„AI Agentä¹‹æ—…ï¼** ğŸš€

