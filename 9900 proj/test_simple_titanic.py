#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•Titanicé—®é¢˜
ç›´æ¥æµ‹è¯•ä»£ç ç”Ÿæˆï¼Œä¸è¿è¡Œå®Œæ•´æµç¨‹
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
import os

def test_titanic_simple():
    """ç®€å•æµ‹è¯•Titanicæ•°æ®å¤„ç†"""
    
    print("ğŸ§ª ç®€å•æµ‹è¯•Titanicæ•°æ®å¤„ç†")
    print("=" * 50)
    
    # æ•°æ®è·¯å¾„
    input_path = '/Users/zhouzhuotao/9900pj/data/competitions/titanic'
    
    # åŠ è½½æ•°æ®
    train = pd.read_csv(os.path.join(input_path, 'train.csv'))
    test = pd.read_csv(os.path.join(input_path, 'test.csv'))
    
    print(f"âœ… è®­ç»ƒæ•°æ®å½¢çŠ¶: {train.shape}")
    print(f"âœ… æµ‹è¯•æ•°æ®å½¢çŠ¶: {test.shape}")
    print(f"âœ… è®­ç»ƒæ•°æ®åˆ—: {list(train.columns)}")
    print(f"âœ… æµ‹è¯•æ•°æ®åˆ—: {list(test.columns)}")
    
    # ç‰¹å¾å·¥ç¨‹
    def feature_engineering(df):
        df = df.copy()  # é¿å…SettingWithCopyWarning
        df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
        df['IsAlone'] = 1
        df.loc[df['FamilySize'] > 1, 'IsAlone'] = 0
        df['Fare'] = df['Fare'].fillna(df['Fare'].median())
        df['Age'] = df['Age'].fillna(df['Age'].median())
        df['Embarked'] = df['Embarked'].fillna('S')
        return df
    
    train = feature_engineering(train)
    test = feature_engineering(test)
    
    print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ")
    
    # ç¼–ç objectåˆ—
    train = pd.get_dummies(train, columns=['Sex', 'Embarked'], drop_first=True)
    test = pd.get_dummies(test, columns=['Sex', 'Embarked'], drop_first=True)
    
    print(f"âœ… ç¼–ç å®Œæˆ")
    print(f"âœ… è®­ç»ƒæ•°æ®åˆ—æ•°: {len(train.columns)}")
    print(f"âœ… æµ‹è¯•æ•°æ®åˆ—æ•°: {len(test.columns)}")
    
    # ä½¿ç”¨inner joinå¯¹é½åˆ—ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
    common_cols = list(set(train.columns) & set(test.columns))
    print(f"âœ… å…±åŒåˆ—æ•°: {len(common_cols)}")
    print(f"âœ… å…±åŒåˆ—: {sorted(common_cols)}")
    
    # åªä¿ç•™å…±åŒåˆ—
    train_aligned = train[common_cols]
    test_aligned = test[common_cols]
    
    print(f"âœ… å¯¹é½åè®­ç»ƒæ•°æ®å½¢çŠ¶: {train_aligned.shape}")
    print(f"âœ… å¯¹é½åæµ‹è¯•æ•°æ®å½¢çŠ¶: {test_aligned.shape}")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    feature_cols = [col for col in common_cols if col not in ['PassengerId', 'Name', 'Ticket', 'Cabin']]
    print(f"âœ… ç‰¹å¾åˆ—: {feature_cols}")
    
    X = train_aligned[feature_cols]
    y = train['Survived']  # ç›´æ¥ä»åŸå§‹è®­ç»ƒæ•°æ®è·å–ç›®æ ‡å˜é‡
    X_test = test_aligned[feature_cols]
    
    print(f"âœ… è®­ç»ƒç‰¹å¾å½¢çŠ¶: {X.shape}")
    print(f"âœ… æµ‹è¯•ç‰¹å¾å½¢çŠ¶: {X_test.shape}")
    print(f"âœ… ç›®æ ‡å˜é‡å½¢çŠ¶: {y.shape}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
    print(f"âœ… è®­ç»ƒç‰¹å¾ç¼ºå¤±å€¼: {X.isnull().sum().sum()}")
    print(f"âœ… æµ‹è¯•ç‰¹å¾ç¼ºå¤±å€¼: {X_test.isnull().sum().sum()}")
    
    # æ¨¡å‹è®­ç»ƒ
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, y)
    
    # é¢„æµ‹
    predictions = model.predict(X_test)
    
    print(f"âœ… é¢„æµ‹å®Œæˆï¼Œé¢„æµ‹å€¼èŒƒå›´: {predictions.min()} - {predictions.max()}")
    print(f"âœ… é¢„æµ‹å€¼åˆ†å¸ƒ: {np.bincount(predictions)}")
    
    # ç”Ÿæˆæäº¤æ–‡ä»¶
    submission = pd.DataFrame({
        'PassengerId': test['PassengerId'],
        'Survived': predictions
    })
    
    output_path = '/Users/zhouzhuotao/9900pj/test_submission.csv'
    submission.to_csv(output_path, index=False)
    
    print(f"âœ… æäº¤æ–‡ä»¶ç”Ÿæˆ: {output_path}")
    print(f"âœ… æäº¤æ–‡ä»¶å½¢çŠ¶: {submission.shape}")
    print(f"âœ… æäº¤æ–‡ä»¶å‰5è¡Œ:")
    print(submission.head())
    
    return True

if __name__ == "__main__":
    try:
        success = test_titanic_simple()
        if success:
            print("\nğŸ‰ ç®€å•æµ‹è¯•æˆåŠŸï¼")
        else:
            print("\nâŒ ç®€å•æµ‹è¯•å¤±è´¥ï¼")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
